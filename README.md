# Multi-Modal Mutual Information (MuMMI) Training for Robust Self-Supervised Deep Reinforcement Learning

This refined repository contains the code for the paper [Multi-Modal Mutual Information (MuMMI) Training for Robust Self-Supervised Deep Reinforcement Learning](https://arxiv.org/abs/2107.02339) (ICRA-21).

## Introduction

This work focuses on learning useful and robust deep world models using multiple, possibly unreliable, sensors. We find that current methods do not sufficiently encourage a shared representation between modalities; this can cause poor performance on downstream tasks and over-reliance on specific sensors. This version of the codebase brings improvements on these fronts and aims to further enhance the results produced by the method.

## Environment Setup

The code is tested on Ubuntu 16.04, Python 3.7 and CUDA 10.2. Please download the relevant Python packages by running the mentioned commands.

## Usage

To run this codebase or baselines on mujoco, follow the steps outlined in the Usage Instructions section.

### BibTeX

To cite this work, please use the following citation:

```
@inproceedings{